\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\catcode`"\active
\citation{abnt-url-package=hyperref}
\citation{abnt-nbr10520=2002}
\citation{abnt-repeated-author-omit=yes}
\select@language{brazil}
\@writefile{toc}{\select@language{brazil}}
\@writefile{lof}{\select@language{brazil}}
\@writefile{lot}{\select@language{brazil}}
\citation{sutton1998reinforcement}
\@writefile{toc}{\contentsline {chapter}{Lista de Ilustrações}{}{chapter.0}}
\@writefile{toc}{\contentsline {chapter}{Lista de Tabelas}{}{chapter.0}}
\@writefile{toc}{\contentsline {chapter}{Lista de Abreviaturas e Siglas}{}{chapter.0}}
\@writefile{toc}{\contentsline {chapter}{Lista de Símbolos}{}{chapter.0}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introdu\c c\~ao}{11}{chapter.1}}
\newlabel{chp:intro}{{1}{11}{Introdução\relax }{chapter.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Aprendizado por Refor\c co}{13}{chapter.2}}
\newlabel{chp:aprendizado_reforco}{{2}{13}{Aprendizado por Reforço\relax }{chapter.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Modelo padr\~ao de Aprendizado por Refor\c co -- neste modelo tem-se o agente B interagindo com o ambiente T; o agente percebe o estado atual s atrav\'es da entrada i, executa uma a\c c\~ao a, observa o novo estado e recebe uma recompensa r.}}{14}{figure.2.1}}
\newlabel{fig:modelo_aprendizado_reforco}{{1}{14}{Modelo padrão de Aprendizado por Reforço -- neste modelo tem-se o agente B interagindo com o ambiente T; o agente percebe o estado atual s através da entrada i, executa uma ação a, observa o novo estado e recebe uma recompensa r}{figure.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Processos de Decis\~ao de Markov}{15}{section.2.1}}
\newlabel{sec:processos_markov}{{2.1}{15}{Aprendizado por Reforço\relax }{section.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Pol\IeC {\'\i }tica \'otima}{15}{section.2.2}}
\newlabel{sec:politica_otima}{{2.2}{15}{Aprendizado por Reforço\relax }{section.2.2}{}}
\newlabel{eq:recompensas_futuras}{{2.1}{16}{Aprendizado por Reforço\relax }{equation.2.2.1}{}}
\newlabel{eq:valor_estado}{{2.2}{16}{Aprendizado por Reforço\relax }{equation.2.2.2}{}}
\newlabel{eq:valor_acao}{{2.3}{17}{Aprendizado por Reforço\relax }{equation.2.2.3}{}}
\newlabel{eq:pre_politica_otima}{{2.4}{17}{Aprendizado por Reforço\relax }{equation.2.2.4}{}}
\newlabel{eq:politica_otima}{{2.5}{17}{Aprendizado por Reforço\relax }{equation.2.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}M\'etodo de solu\c c\~ao}{18}{section.2.3}}
\newlabel{sec:metodo_solucao}{{2.3}{18}{Aprendizado por Reforço\relax }{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Programa\c c\~ao din\^amica}{18}{subsection.2.3.1}}
\newlabel{sec:prog_dinamica}{{2.3.1}{18}{Aprendizado por Reforço\relax }{subsection.2.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}M\'etodos de Monte Carlo}{19}{subsection.2.3.2}}
\newlabel{sec:monte_carlo}{{2.3.2}{19}{Aprendizado por Reforço\relax }{subsection.2.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Aprendizado por diferen\c ca temporal}{19}{subsection.2.3.3}}
\newlabel{sec:diferenca_temporal}{{2.3.3}{19}{Aprendizado por Reforço\relax }{subsection.2.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3.1}Predi\c c\~ao DT}{20}{subsubsection.2.3.3.1}}
\newlabel{eq:dt0}{{2.6}{20}{Aprendizado por Reforço\relax }{equation.2.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3.2}Off-Policy e Q-Learning}{21}{subsubsection.2.3.3.2}}
\newlabel{eq:q_learning}{{2.7}{22}{Aprendizado por Reforço\relax }{equation.2.3.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3.3}On-Policy SARSA-Learning}{22}{subsubsection.2.3.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Abstra\c c\~ao utilizada para compreens\~ao de onde exatamente encontram-se o valor-estado e o valor-a\c c\~ao.}}{22}{figure.2.2}}
\newlabel{fig:abst_valor_estado_acao}{{2}{22}{Abstração utilizada para compreensão de onde exatamente encontram-se o valor-estado e o valor-ação}{figure.2.2}{}}
\newlabel{eq:sarsa}{{2.8}{23}{Aprendizado por Reforço\relax }{equation.2.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Tra\c cos de elegibilidade}{23}{subsection.2.3.4}}
\newlabel{sec:traco_elegibilidade}{{2.3.4}{23}{Aprendizado por Reforço\relax }{subsection.2.3.4}{}}
\citation{sutton1998reinforcement}
\citation{sutton1998reinforcement}
\citation{sutton1998reinforcement}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4.1}Predi\c c\~ao por DT de n passos}{24}{subsubsection.2.3.4.1}}
\citation{sutton1998reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Modelo formado por estados e transi\c c\~oes considerados em m\'etodos por DT de 1 \'unico passo at\'e n passos para a predi\c c\~ao por DT \cite  {sutton1998reinforcement}.}}{25}{figure.2.3}}
\newlabel{fig:modelo_predicao_dt}{{3}{25}{Modelo formado por estados e transições considerados em métodos por DT de 1 único passo até n passos para a predição por DT \cite {sutton1998reinforcement}}{figure.2.3}{}}
\newlabel{eq:predicao_dt_1_passo}{{2.9}{25}{Aprendizado por Reforço\relax }{equation.2.3.9}{}}
\newlabel{eq:predicao_dt_n_passo}{{2.10}{25}{Aprendizado por Reforço\relax }{equation.2.3.10}{}}
\newlabel{eq:incremento_valor_estado}{{2.11}{26}{Aprendizado por Reforço\relax }{equation.2.3.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4.2}A vis\~ao diante de DT($\lambda $)}{26}{subsubsection.2.3.4.2}}
\newlabel{sec:visao_diante_dt}{{2.3.4.2}{26}{Aprendizado por Reforço\relax }{subsubsection.2.3.4.2}{}}
\newlabel{eq:media_2_4_passos}{{2.12}{26}{Aprendizado por Reforço\relax }{equation.2.3.12}{}}
\citation{sutton1998reinforcement}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Diagrama de m\'etodos por DT($\lambda $) com atribui\c c\~ao de pesos a cada estrutura de n passos.}}{27}{figure.2.4}}
\newlabel{fig:diagrama_dt_com_pesos}{{4}{27}{Diagrama de métodos por DT($\lambda $) com atribuição de pesos a cada estrutura de n passos}{figure.2.4}{}}
\newlabel{eq:retorno_lambda}{{2.13}{27}{Aprendizado por Reforço\relax }{equation.2.3.13}{}}
\newlabel{eq:incremento_valor_estado_lambda}{{2.14}{27}{Aprendizado por Reforço\relax }{equation.2.3.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Ilustra\c c\~ao de como funciona a vis\~ao adiante -- o agente deve olhar apenas o panorama futuro para suas considera\c c\~oes atuais.}}{28}{figure.2.5}}
\newlabel{fig:visao_adiante}{{5}{28}{Ilustração de como funciona a visão adiante -- o agente deve olhar apenas o panorama futuro para suas considerações atuais}{figure.2.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4.3}A vis\~ao retr\'ograda de DT($\lambda $)}{28}{subsubsection.2.3.4.3}}
\newlabel{eq:traco_elegibilidade}{{2.15}{28}{Aprendizado por Reforço\relax }{equation.2.3.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Gr\'afico explicativo sobre como o valor do tra\c co de elegibilidade varia caso ocorram visitas a um mesmo estado.}}{29}{figure.2.6}}
\newlabel{fig:grafico_elegibilidade}{{6}{29}{Gráfico explicativo sobre como o valor do traço de elegibilidade varia caso ocorram visitas a um mesmo estado}{figure.2.6}{}}
\newlabel{eq:incremento_valor_estado_elegib_parcial}{{2.16}{29}{Aprendizado por Reforço\relax }{equation.2.3.16}{}}
\citation{sutton1998reinforcement}
\newlabel{eq:incremento_valor_estado_elegibilidade}{{2.17}{30}{Aprendizado por Reforço\relax }{equation.2.3.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Ilustra\c c\~ao de como funciona a vis\~ao retr\'ograda de m\'etodos por DT -- o agente deve passar aos estados anteriores a sua situa\c c\~ao atual.}}{30}{figure.2.7}}
\newlabel{fig:visao_retrograda}{{7}{30}{Ilustração de como funciona a visão retrógrada de métodos por DT -- o agente deve passar aos estados anteriores a sua situação atual}{figure.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}SARSA($\lambda $)}{31}{subsection.2.3.5}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}CMAC}{32}{chapter.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Navega\c c\~ao rob\'otica}{33}{chapter.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}ROS}{33}{section.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Mensagens e servidores}{34}{subsection.4.1.1}}
\citation{ortiz2008relational}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Scripts}{35}{subsection.4.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Defini\c c\~ao de estados}{35}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Simulador TurtleSim sendo executado. Aqui o rono est\'a fazendo uma rota circular, assim como no trajeto desenhado.}}{36}{figure.4.8}}
\newlabel{fig:turtlesim}{{8}{36}{Simulador TurtleSim sendo executado. Aqui o rono está fazendo uma rota circular, assim como no trajeto desenhado}{figure.4.8}{}}
\citation{arkin1998behavior}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Arquitetura}{37}{section.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Sistema rob\'otico a ser utilizado neste projeto (Pioneer 2DX) -- neste exemplo o rob\^o j\'a possui uma c\^amera auxiliar e podemos visualizar os sensores acoplados ao rob\^o.}}{38}{figure.4.9}}
\newlabel{fig:pioneer_2dx}{{9}{38}{Sistema robótico a ser utilizado neste projeto (Pioneer 2DX) -- neste exemplo o robô já possui uma câmera auxiliar e podemos visualizar os sensores acoplados ao robô}{figure.4.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Proposta}{39}{chapter.5}}
\bibdata{abnt-options,Monografia}
\bibcite{arkin1998behavior}{Arkin 1998}
\bibciteEXPL{arkin1998behavior}{Arkin}
\bibciteIMPL{arkin1998behavior}{ARKIN}
\bibciteYEAR{arkin1998behavior}{1998}
\bibcite{ortiz2008relational}{Ortiz, Garc{\'\i }a e Borrajo 2008}
\bibciteEXPL{ortiz2008relational}{Ortiz, Garc{\'\i }a e Borrajo}
\bibciteIMPL{ortiz2008relational}{ORTIZ; GARC{\'I}A; BORRAJO}
\bibciteYEAR{ortiz2008relational}{2008}
\bibcite{sutton1998reinforcement}{Sutton e Barto 1998}
\bibciteEXPL{sutton1998reinforcement}{Sutton e Barto}
\bibciteIMPL{sutton1998reinforcement}{SUTTON; BARTO}
\bibciteYEAR{sutton1998reinforcement}{1998}
\@writefile{toc}{\contentsline {chapter}{Refer\^encias}{42}{chapter.5}}
\newlabel{LastPage}{{}{42}{}{page.42}{}}
\xdef\lastpage@lastpage{42}
\xdef\lastpage@lastpageHy{42}
\bibstyle{abnt-alf}
