\select@language {brazil}
\contentsline {figure}{\numberline {1}{\ignorespaces Modelo padr\~ao de Aprendizado por Refor\c co -- neste modelo tem-se o agente B interagindo com o ambiente T; o agente percebe o estado atual s atrav\'es da entrada i, executa uma a\c c\~ao a, observa o novo estado e recebe uma recompensa r.}}{14}{figure.2.1}
\contentsline {figure}{\numberline {2}{\ignorespaces Abstra\c c\~ao utilizada para compreens\~ao de onde exatamente encontram-se o valor-estado e o valor-a\c c\~ao.}}{22}{figure.2.2}
\contentsline {figure}{\numberline {3}{\ignorespaces Modelo formado por estados e transi\c c\~oes considerados em m\'etodos por DT de 1 \'unico passo at\'e n passos para a predi\c c\~ao por DT \cite {sutton1998reinforcement}.}}{25}{figure.2.3}
\contentsline {figure}{\numberline {4}{\ignorespaces Diagrama de m\'etodos por DT($\lambda $) com atribui\c c\~ao de pesos a cada estrutura de n passos.}}{27}{figure.2.4}
\contentsline {figure}{\numberline {5}{\ignorespaces Ilustra\c c\~ao de como funciona a vis\~ao adiante -- o agente deve olhar apenas o panorama futuro para suas considera\c c\~oes atuais.}}{28}{figure.2.5}
\contentsline {figure}{\numberline {6}{\ignorespaces Gr\'afico explicativo sobre como o valor do tra\c co de elegibilidade varia caso ocorram visitas a um mesmo estado.}}{29}{figure.2.6}
\contentsline {figure}{\numberline {7}{\ignorespaces Ilustra\c c\~ao de como funciona a vis\~ao retr\'ograda de m\'etodos por DT -- o agente deve passar aos estados anteriores a sua situa\c c\~ao atual.}}{30}{figure.2.7}
\contentsline {figure}{\numberline {8}{\ignorespaces Simulador TurtleSim sendo executado. Aqui o rono est\'a fazendo uma rota circular, assim como no trajeto desenhado.}}{36}{figure.4.8}
\contentsline {figure}{\numberline {9}{\ignorespaces Sistema rob\'otico a ser utilizado neste projeto (Pioneer 2DX) -- neste exemplo o rob\^o j\'a possui uma c\^amera auxiliar e podemos visualizar os sensores acoplados ao rob\^o.}}{38}{figure.4.9}
